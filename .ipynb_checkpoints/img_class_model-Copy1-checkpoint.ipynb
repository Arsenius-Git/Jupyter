{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2782634b-3c33-4ccc-8172-5b290c28574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arsen\\PycharmProjects\\PythonProject2\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7233b0ca-9d1d-4133-8769-3d9cd9866fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparams \n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "validation_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c4b4104-6e6d-46a3-b1ba-0b6ee2b5eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "256fe92f-ca80-4106-8676-b7de48b019dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\python\\datasets_storage'\n",
    "test_data = torchvision.datasets.CIFAR100(root=path,train=False,download=True, transform=transform)\n",
    "dataset_train = torchvision.datasets.CIFAR100(root=path,train=True,download=True, transform=transform)\n",
    "\n",
    "train_data,validation_data=torch.utils.data.random_split(dataset_train,[int((1-validation_ratio)*len(dataset_train)), int((validation_ratio)*len(dataset_train))])\n",
    "print(len(validation_data))\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ac711f6-648c-4a85-9966-45f3ca80e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, pin_memory=True, shuffle=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=batch_size, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size,shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35607460-4344-4279-be1a-a9fd36ce2afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_device():\n",
    "    if torch.cuda.is_available:\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "def move_device(tensor,device):\n",
    "    if isinstance(tensor,(list,tuple)):    \n",
    "      return[move_device(element,device) for element in tensor]  \n",
    "    return tensor.to(device,non_blocking=True)\n",
    "class DeviceDataloader():\n",
    "    def __init__(self,dataloader,device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "    def __iter__(self):\n",
    "        # transfer ecach batch and return\n",
    "        for i in self.dataloader:\n",
    "           yield move_device(i, self.device)\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.dataloader)\n",
    "device = check_device()\n",
    "\n",
    "train_dl = DeviceDataloader(train_loader, device)\n",
    "test_dl = DeviceDataloader(test_loader, device)\n",
    "val_dl  = DeviceDataloader(val_loader, device)\n",
    "#len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6ac72ca-658e-4268-9098-4081aaa39bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_model(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (hidden_layer): Linear(in_features=512, out_features=206, bias=True)\n",
      "  (output_layer): Linear(in_features=206, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_model,self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size = 2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size = 2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2)\n",
    "        )\n",
    "        self.hidden_layer = nn.Linear(128 * 2 * 2, 206)\n",
    "        self.output_layer = nn.Linear(206 , 100)\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2(output)\n",
    "        output = self.conv3(output)\n",
    "        output = self.conv4(output)\n",
    "        #flattening \n",
    "        output = output.view(-1, 128 * 2 * 2)\n",
    "        # fully connected layers\n",
    "        output = self.hidden_layer(output)\n",
    "        output = self.output_layer(output)\n",
    "        return output\n",
    "model = CNN_model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eeb8c85-228f-4930-9e05-e2e3595089a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr= 1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5d6c0ae-fb48-48a9-a793-3f5256ab9112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda if torch.cuda.is_available() else \"CUDA not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96a12572-66f4-48e3-81a7-54fd13358283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n"
     ]
    }
   ],
   "source": [
    "print('Starting...')\n",
    "epochs = 51\n",
    "model = model.to(device)\n",
    "def model_train(model, train_loader, criterion, optimizer):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx,(images,targets) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            images,targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            batch_idx += 1\n",
    "    \n",
    "            if batch_idx % 400 == 0:\n",
    "                print(f'Epoch\" {epoch + 1}/{epochs} | Loss:{running_loss} | '\n",
    "                      f'Loss: {running_loss / (batch_idx+1):.4f} | '\n",
    "                      f'Acc: {100.*correct/total:.2f}% | '\n",
    "                      f'Batch: {batch_idx / len(train_loader)}')\n",
    "        print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8065a7dd-4e89-47e9-b09c-e66801e1de31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch\" 1/51 | Loss:1842.6186017990112 | Loss: 4.5951 | Acc: 0.64% | Batch: 0.32\n",
      "Epoch\" 1/51 | Loss:3684.960832118988 | Loss: 4.6005 | Acc: 0.65% | Batch: 0.64\n",
      "Epoch\" 1/51 | Loss:5527.6469712257385 | Loss: 4.6025 | Acc: 0.68% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 2/51 | Loss:1842.6927218437195 | Loss: 4.5952 | Acc: 0.65% | Batch: 0.32\n",
      "Epoch\" 2/51 | Loss:3685.0366411209106 | Loss: 4.6005 | Acc: 0.79% | Batch: 0.64\n",
      "Epoch\" 2/51 | Loss:5527.245454311371 | Loss: 4.6022 | Acc: 0.75% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 3/51 | Loss:1842.4761199951172 | Loss: 4.5947 | Acc: 0.68% | Batch: 0.32\n",
      "Epoch\" 3/51 | Loss:3684.5460934638977 | Loss: 4.5999 | Acc: 0.73% | Batch: 0.64\n",
      "Epoch\" 3/51 | Loss:5526.983001232147 | Loss: 4.6020 | Acc: 0.77% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 4/51 | Loss:1842.2277455329895 | Loss: 4.5941 | Acc: 0.89% | Batch: 0.32\n",
      "Epoch\" 4/51 | Loss:3684.4518666267395 | Loss: 4.5998 | Acc: 0.85% | Batch: 0.64\n",
      "Epoch\" 4/51 | Loss:5526.635514259338 | Loss: 4.6017 | Acc: 0.84% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 5/51 | Loss:1842.198899269104 | Loss: 4.5940 | Acc: 0.89% | Batch: 0.32\n",
      "Epoch\" 5/51 | Loss:3684.2607798576355 | Loss: 4.5996 | Acc: 0.88% | Batch: 0.64\n",
      "Epoch\" 5/51 | Loss:5526.215416431427 | Loss: 4.6013 | Acc: 0.91% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 6/51 | Loss:1842.010196685791 | Loss: 4.5935 | Acc: 0.79% | Batch: 0.32\n",
      "Epoch\" 6/51 | Loss:3684.0731525421143 | Loss: 4.5993 | Acc: 0.90% | Batch: 0.64\n",
      "Epoch\" 6/51 | Loss:5525.811575889587 | Loss: 4.6010 | Acc: 0.94% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 7/51 | Loss:1842.0711069107056 | Loss: 4.5937 | Acc: 0.93% | Batch: 0.32\n",
      "Epoch\" 7/51 | Loss:3683.534291744232 | Loss: 4.5987 | Acc: 1.01% | Batch: 0.64\n",
      "Epoch\" 7/51 | Loss:5525.260091781616 | Loss: 4.6005 | Acc: 1.00% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 8/51 | Loss:1841.6883153915405 | Loss: 4.5927 | Acc: 0.96% | Batch: 0.32\n",
      "Epoch\" 8/51 | Loss:3683.4454889297485 | Loss: 4.5986 | Acc: 1.02% | Batch: 0.64\n",
      "Epoch\" 8/51 | Loss:5524.816904067993 | Loss: 4.6002 | Acc: 1.04% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 9/51 | Loss:1841.5544700622559 | Loss: 4.5924 | Acc: 0.92% | Batch: 0.32\n",
      "Epoch\" 9/51 | Loss:3682.9371938705444 | Loss: 4.5979 | Acc: 1.02% | Batch: 0.64\n",
      "Epoch\" 9/51 | Loss:5523.982372283936 | Loss: 4.5995 | Acc: 1.04% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 10/51 | Loss:1841.235538482666 | Loss: 4.5916 | Acc: 1.09% | Batch: 0.32\n",
      "Epoch\" 10/51 | Loss:3682.2155570983887 | Loss: 4.5970 | Acc: 1.20% | Batch: 0.64\n",
      "Epoch\" 10/51 | Loss:5523.100629329681 | Loss: 4.5988 | Acc: 1.24% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 11/51 | Loss:1840.8726124763489 | Loss: 4.5907 | Acc: 1.44% | Batch: 0.32\n",
      "Epoch\" 11/51 | Loss:3681.5311374664307 | Loss: 4.5962 | Acc: 1.48% | Batch: 0.64\n",
      "Epoch\" 11/51 | Loss:5522.040149688721 | Loss: 4.5979 | Acc: 1.52% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 12/51 | Loss:1840.3911581039429 | Loss: 4.5895 | Acc: 1.70% | Batch: 0.32\n",
      "Epoch\" 12/51 | Loss:3680.6002340316772 | Loss: 4.5950 | Acc: 1.79% | Batch: 0.64\n",
      "Epoch\" 12/51 | Loss:5520.56911945343 | Loss: 4.5966 | Acc: 1.74% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 13/51 | Loss:1839.3600177764893 | Loss: 4.5869 | Acc: 1.73% | Batch: 0.32\n",
      "Epoch\" 13/51 | Loss:3678.9125599861145 | Loss: 4.5929 | Acc: 1.70% | Batch: 0.64\n",
      "Epoch\" 13/51 | Loss:5518.2667870521545 | Loss: 4.5947 | Acc: 1.71% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 14/51 | Loss:1838.6950497627258 | Loss: 4.5853 | Acc: 1.60% | Batch: 0.32\n",
      "Epoch\" 14/51 | Loss:3676.9014196395874 | Loss: 4.5904 | Acc: 1.57% | Batch: 0.64\n",
      "Epoch\" 14/51 | Loss:5514.874757766724 | Loss: 4.5919 | Acc: 1.51% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 15/51 | Loss:1837.0663771629333 | Loss: 4.5812 | Acc: 1.38% | Batch: 0.32\n",
      "Epoch\" 15/51 | Loss:3673.5880370140076 | Loss: 4.5863 | Acc: 1.33% | Batch: 0.64\n",
      "Epoch\" 15/51 | Loss:5509.423738002777 | Loss: 4.5874 | Acc: 1.31% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 16/51 | Loss:1834.1135778427124 | Loss: 4.5738 | Acc: 1.34% | Batch: 0.32\n",
      "Epoch\" 16/51 | Loss:3668.0980248451233 | Loss: 4.5794 | Acc: 1.17% | Batch: 0.64\n",
      "Epoch\" 16/51 | Loss:5501.263502597809 | Loss: 4.5806 | Acc: 1.14% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 17/51 | Loss:1830.8883600234985 | Loss: 4.5658 | Acc: 1.20% | Batch: 0.32\n",
      "Epoch\" 17/51 | Loss:3660.5501732826233 | Loss: 4.5700 | Acc: 1.11% | Batch: 0.64\n",
      "Epoch\" 17/51 | Loss:5489.70258140564 | Loss: 4.5709 | Acc: 1.12% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 18/51 | Loss:1827.3960990905762 | Loss: 4.5571 | Acc: 1.16% | Batch: 0.32\n",
      "Epoch\" 18/51 | Loss:3653.9558453559875 | Loss: 4.5617 | Acc: 1.14% | Batch: 0.64\n",
      "Epoch\" 18/51 | Loss:5477.940137386322 | Loss: 4.5611 | Acc: 1.19% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 19/51 | Loss:1823.6861939430237 | Loss: 4.5478 | Acc: 1.18% | Batch: 0.32\n",
      "Epoch\" 19/51 | Loss:3643.540695667267 | Loss: 4.5487 | Acc: 1.32% | Batch: 0.64\n",
      "Epoch\" 19/51 | Loss:5464.506707191467 | Loss: 4.5500 | Acc: 1.46% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 20/51 | Loss:1817.2483105659485 | Loss: 4.5318 | Acc: 1.77% | Batch: 0.32\n",
      "Epoch\" 20/51 | Loss:3634.399006843567 | Loss: 4.5373 | Acc: 1.71% | Batch: 0.64\n",
      "Epoch\" 20/51 | Loss:5446.748749732971 | Loss: 4.5352 | Acc: 1.82% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 21/51 | Loss:1811.3357071876526 | Loss: 4.5170 | Acc: 2.19% | Batch: 0.32\n",
      "Epoch\" 21/51 | Loss:3618.6156277656555 | Loss: 4.5176 | Acc: 2.20% | Batch: 0.64\n",
      "Epoch\" 21/51 | Loss:5424.389849185944 | Loss: 4.5166 | Acc: 2.22% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 22/51 | Loss:1801.3181285858154 | Loss: 4.4921 | Acc: 2.52% | Batch: 0.32\n",
      "Epoch\" 22/51 | Loss:3596.8679399490356 | Loss: 4.4905 | Acc: 2.73% | Batch: 0.64\n",
      "Epoch\" 22/51 | Loss:5390.623857498169 | Loss: 4.4884 | Acc: 2.78% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 23/51 | Loss:1783.508150100708 | Loss: 4.4477 | Acc: 3.16% | Batch: 0.32\n",
      "Epoch\" 23/51 | Loss:3564.9254689216614 | Loss: 4.4506 | Acc: 3.38% | Batch: 0.64\n",
      "Epoch\" 23/51 | Loss:5340.490802288055 | Loss: 4.4467 | Acc: 3.38% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 24/51 | Loss:1765.3766055107117 | Loss: 4.4024 | Acc: 3.74% | Batch: 0.32\n",
      "Epoch\" 24/51 | Loss:3525.344642162323 | Loss: 4.4012 | Acc: 3.96% | Batch: 0.64\n",
      "Epoch\" 24/51 | Loss:5274.956735610962 | Loss: 4.3921 | Acc: 4.22% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 25/51 | Loss:1742.7695837020874 | Loss: 4.3461 | Acc: 4.91% | Batch: 0.32\n",
      "Epoch\" 25/51 | Loss:3479.330545902252 | Loss: 4.3437 | Acc: 4.93% | Batch: 0.64\n",
      "Epoch\" 25/51 | Loss:5208.821952342987 | Loss: 4.3371 | Acc: 5.00% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 26/51 | Loss:1723.6017367839813 | Loss: 4.2983 | Acc: 5.09% | Batch: 0.32\n",
      "Epoch\" 26/51 | Loss:3439.758278608322 | Loss: 4.2943 | Acc: 5.27% | Batch: 0.64\n",
      "Epoch\" 26/51 | Loss:5150.8638825416565 | Loss: 4.2888 | Acc: 5.37% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 27/51 | Loss:1704.1057767868042 | Loss: 4.2496 | Acc: 6.14% | Batch: 0.32\n",
      "Epoch\" 27/51 | Loss:3404.5798993110657 | Loss: 4.2504 | Acc: 5.89% | Batch: 0.64\n",
      "Epoch\" 27/51 | Loss:5093.714703321457 | Loss: 4.2412 | Acc: 5.93% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 28/51 | Loss:1681.5859627723694 | Loss: 4.1935 | Acc: 6.40% | Batch: 0.32\n",
      "Epoch\" 28/51 | Loss:3360.6405589580536 | Loss: 4.1956 | Acc: 6.38% | Batch: 0.64\n",
      "Epoch\" 28/51 | Loss:5033.666301250458 | Loss: 4.1912 | Acc: 6.44% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 29/51 | Loss:1658.4710764884949 | Loss: 4.1358 | Acc: 6.85% | Batch: 0.32\n",
      "Epoch\" 29/51 | Loss:3322.2143557071686 | Loss: 4.1476 | Acc: 7.05% | Batch: 0.64\n",
      "Epoch\" 29/51 | Loss:4976.01117348671 | Loss: 4.1432 | Acc: 7.09% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 30/51 | Loss:1648.5311441421509 | Loss: 4.1111 | Acc: 7.57% | Batch: 0.32\n",
      "Epoch\" 30/51 | Loss:3290.0363762378693 | Loss: 4.1074 | Acc: 7.69% | Batch: 0.64\n",
      "Epoch\" 30/51 | Loss:4925.044899225235 | Loss: 4.1008 | Acc: 7.82% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 31/51 | Loss:1631.1786630153656 | Loss: 4.0678 | Acc: 8.49% | Batch: 0.32\n",
      "Epoch\" 31/51 | Loss:3257.8879718780518 | Loss: 4.0673 | Acc: 8.38% | Batch: 0.64\n",
      "Epoch\" 31/51 | Loss:4879.992275238037 | Loss: 4.0633 | Acc: 8.43% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 32/51 | Loss:1615.750964641571 | Loss: 4.0293 | Acc: 8.56% | Batch: 0.32\n",
      "Epoch\" 32/51 | Loss:3226.310440301895 | Loss: 4.0279 | Acc: 8.97% | Batch: 0.64\n",
      "Epoch\" 32/51 | Loss:4838.5504949092865 | Loss: 4.0288 | Acc: 8.99% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 33/51 | Loss:1602.4594745635986 | Loss: 3.9962 | Acc: 9.23% | Batch: 0.32\n",
      "Epoch\" 33/51 | Loss:3202.5356533527374 | Loss: 3.9982 | Acc: 9.32% | Batch: 0.64\n",
      "Epoch\" 33/51 | Loss:4803.568541765213 | Loss: 3.9996 | Acc: 9.36% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 34/51 | Loss:1588.3304767608643 | Loss: 3.9609 | Acc: 9.70% | Batch: 0.32\n",
      "Epoch\" 34/51 | Loss:3182.9298796653748 | Loss: 3.9737 | Acc: 9.67% | Batch: 0.64\n",
      "Epoch\" 34/51 | Loss:4770.593668937683 | Loss: 3.9722 | Acc: 9.72% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 35/51 | Loss:1587.3134396076202 | Loss: 3.9584 | Acc: 10.20% | Batch: 0.32\n",
      "Epoch\" 35/51 | Loss:3167.037831068039 | Loss: 3.9539 | Acc: 10.03% | Batch: 0.64\n",
      "Epoch\" 35/51 | Loss:4740.3754942417145 | Loss: 3.9470 | Acc: 10.12% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 36/51 | Loss:1569.3275134563446 | Loss: 3.9135 | Acc: 10.75% | Batch: 0.32\n",
      "Epoch\" 36/51 | Loss:3140.381039619446 | Loss: 3.9206 | Acc: 10.50% | Batch: 0.64\n",
      "Epoch\" 36/51 | Loss:4708.58718752861 | Loss: 3.9206 | Acc: 10.57% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 37/51 | Loss:1568.6399240493774 | Loss: 3.9118 | Acc: 10.22% | Batch: 0.32\n",
      "Epoch\" 37/51 | Loss:3122.0409319400787 | Loss: 3.8977 | Acc: 10.76% | Batch: 0.64\n",
      "Epoch\" 37/51 | Loss:4681.22959280014 | Loss: 3.8978 | Acc: 10.91% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 38/51 | Loss:1555.255488395691 | Loss: 3.8784 | Acc: 10.90% | Batch: 0.32\n",
      "Epoch\" 38/51 | Loss:3101.5846378803253 | Loss: 3.8721 | Acc: 11.13% | Batch: 0.64\n",
      "Epoch\" 38/51 | Loss:4648.063667297363 | Loss: 3.8702 | Acc: 11.27% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 39/51 | Loss:1541.722000360489 | Loss: 3.8447 | Acc: 11.19% | Batch: 0.32\n",
      "Epoch\" 39/51 | Loss:3083.71435546875 | Loss: 3.8498 | Acc: 11.56% | Batch: 0.64\n",
      "Epoch\" 39/51 | Loss:4619.735839366913 | Loss: 3.8466 | Acc: 11.66% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 40/51 | Loss:1534.2440338134766 | Loss: 3.8260 | Acc: 11.66% | Batch: 0.32\n",
      "Epoch\" 40/51 | Loss:3063.0681805610657 | Loss: 3.8241 | Acc: 11.84% | Batch: 0.64\n",
      "Epoch\" 40/51 | Loss:4588.058069229126 | Loss: 3.8202 | Acc: 12.17% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 41/51 | Loss:1518.6959357261658 | Loss: 3.7873 | Acc: 12.59% | Batch: 0.32\n",
      "Epoch\" 41/51 | Loss:3034.1770141124725 | Loss: 3.7880 | Acc: 12.82% | Batch: 0.64\n",
      "Epoch\" 41/51 | Loss:4549.885265350342 | Loss: 3.7884 | Acc: 12.86% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 42/51 | Loss:1513.4517440795898 | Loss: 3.7742 | Acc: 13.27% | Batch: 0.32\n",
      "Epoch\" 42/51 | Loss:3019.7971732616425 | Loss: 3.7700 | Acc: 13.32% | Batch: 0.64\n",
      "Epoch\" 42/51 | Loss:4521.7489676475525 | Loss: 3.7650 | Acc: 13.29% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 43/51 | Loss:1493.9129345417023 | Loss: 3.7255 | Acc: 14.02% | Batch: 0.32\n",
      "Epoch\" 43/51 | Loss:2993.608912706375 | Loss: 3.7373 | Acc: 13.67% | Batch: 0.64\n",
      "Epoch\" 43/51 | Loss:4485.724980831146 | Loss: 3.7350 | Acc: 13.75% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 44/51 | Loss:1484.848394393921 | Loss: 3.7029 | Acc: 14.41% | Batch: 0.32\n",
      "Epoch\" 44/51 | Loss:2972.403753042221 | Loss: 3.7109 | Acc: 13.96% | Batch: 0.64\n",
      "Epoch\" 44/51 | Loss:4451.626410484314 | Loss: 3.7066 | Acc: 14.18% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 45/51 | Loss:1471.8380312919617 | Loss: 3.6704 | Acc: 14.62% | Batch: 0.32\n",
      "Epoch\" 45/51 | Loss:2946.3761706352234 | Loss: 3.6784 | Acc: 14.68% | Batch: 0.64\n",
      "Epoch\" 45/51 | Loss:4419.763267755508 | Loss: 3.6801 | Acc: 14.59% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 46/51 | Loss:1466.0774812698364 | Loss: 3.6561 | Acc: 15.34% | Batch: 0.32\n",
      "Epoch\" 46/51 | Loss:2928.526790857315 | Loss: 3.6561 | Acc: 15.21% | Batch: 0.64\n",
      "Epoch\" 46/51 | Loss:4387.698027849197 | Loss: 3.6534 | Acc: 15.29% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 47/51 | Loss:1458.9866263866425 | Loss: 3.6384 | Acc: 14.94% | Batch: 0.32\n",
      "Epoch\" 47/51 | Loss:2908.3909261226654 | Loss: 3.6309 | Acc: 15.54% | Batch: 0.64\n",
      "Epoch\" 47/51 | Loss:4355.3412075042725 | Loss: 3.6264 | Acc: 15.68% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 48/51 | Loss:1445.9986290931702 | Loss: 3.6060 | Acc: 15.96% | Batch: 0.32\n",
      "Epoch\" 48/51 | Loss:2891.7312672138214 | Loss: 3.6102 | Acc: 16.11% | Batch: 0.64\n",
      "Epoch\" 48/51 | Loss:4327.496390104294 | Loss: 3.6032 | Acc: 16.20% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 49/51 | Loss:1430.9409375190735 | Loss: 3.5684 | Acc: 16.76% | Batch: 0.32\n",
      "Epoch\" 49/51 | Loss:2861.7976973056793 | Loss: 3.5728 | Acc: 16.62% | Batch: 0.64\n",
      "Epoch\" 49/51 | Loss:4295.069653749466 | Loss: 3.5762 | Acc: 16.58% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 50/51 | Loss:1417.4124751091003 | Loss: 3.5347 | Acc: 17.59% | Batch: 0.32\n",
      "Epoch\" 50/51 | Loss:2846.3983845710754 | Loss: 3.5536 | Acc: 17.04% | Batch: 0.64\n",
      "Epoch\" 50/51 | Loss:4266.049954414368 | Loss: 3.5521 | Acc: 16.91% | Batch: 0.96\n",
      "Finished!\n",
      "Epoch\" 51/51 | Loss:1411.6990826129913 | Loss: 3.5204 | Acc: 17.22% | Batch: 0.32\n",
      "Epoch\" 51/51 | Loss:2829.861430644989 | Loss: 3.5329 | Acc: 17.20% | Batch: 0.64\n",
      "Epoch\" 51/51 | Loss:4243.769940376282 | Loss: 3.5335 | Acc: 17.21% | Batch: 0.96\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "model_train(model,train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a901e0-788e-42de-9bc0-c5a3d99005e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
